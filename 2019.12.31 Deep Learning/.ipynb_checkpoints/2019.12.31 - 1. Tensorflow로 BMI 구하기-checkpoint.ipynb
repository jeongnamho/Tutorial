{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow로 bmi판정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 오차 = 108.66269 정확률(평균) = 0.3242\n",
      "Epoch = 500 오차 = 57.58866 정확률(평균) = 0.8904\n",
      "Epoch = 1000 오차 = 45.020916 정확률(평균) = 0.898\n",
      "Epoch = 1500 오차 = 41.654335 정확률(평균) = 0.9566\n",
      "Epoch = 2000 오차 = 34.664024 정확률(평균) = 0.943\n",
      "Epoch = 2500 오차 = 34.287025 정확률(평균) = 0.9674\n",
      "Epoch = 3000 오차 = 26.880762 정확률(평균) = 0.9726\n",
      "Epoch = 3500 오차 = 29.590666 정확률(평균) = 0.9728\n"
     ]
    }
   ],
   "source": [
    "# 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기 \n",
    "df = pd.read_csv(\"./dataset/bmi.csv\")\n",
    "\n",
    "# 키와 몸무게 정규화\n",
    "df[\"height\"] = df['height']/200\n",
    "df['weight'] = df['weight']/100\n",
    "\n",
    "# label 컬럼 변환 - thin[1,0,0] / normal[0,1,0] / fat[0,0,1]\n",
    "bclass = {'thin':[1,0,0], 'normal':[0,1,0], 'fat':[0,0,1]}\n",
    "df[\"label_pat\"] = df[\"label\"].apply(lambda x: np.array(bclass[x]))\n",
    "\n",
    "# 학습데이터와 테스트 데이터 분류\n",
    "test_df = df[15000:20000]\n",
    "test_pat = test_df[['weight', 'height']]\n",
    "test_ans = list(test_df[\"label_pat\"])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2]) # 키, 몸무게 데이터 담을 placeholder 선언\n",
    "Y = tf.placeholder(tf.float32, [None, 3]) # 정답 레이블 데이터 담을 placeholder 선언\n",
    "\n",
    "W = tf.Variable(tf.zeros([2,3]))\n",
    "b = tf.Variable(tf.zeros([3]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(X,W) + b) # 소프트맥스 회귀 정의\n",
    "cross_entropy = -tf.reduce_sum(Y*tf.log(y)) # 오차함수 - 교차 엔트로피\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) # 경사하강법으로 학습\n",
    "\n",
    "# 예측값, 정답률 계산\n",
    "predict = tf.equal(tf.argmax(y,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, tf.float32))\n",
    "\n",
    "# 세션 선언\n",
    "sess = tf.Session()\n",
    "\n",
    "# 변수 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3501):\n",
    "    i = (step*100) % 14000\n",
    "    rows = df[i+1: i+1+100]\n",
    "    x_pat = rows[[\"weight\", 'height']]\n",
    "    y_ans = list(rows[\"label_pat\"])\n",
    "    sess.run(train, feed_dict={X:x_pat ,Y:y_ans})\n",
    "    if step%500 == 0:\n",
    "        cre = sess.run(cross_entropy, feed_dict={X:x_pat ,Y:y_ans})\n",
    "        acc = sess.run(accuracy, feed_dict={X:test_pat ,Y:test_ans})\n",
    "        print(\"Epoch =\", step, \"오차 =\",cre, \"정확률(평균) =\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras + tensorflow로 bmi 판정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\.conda\\envs\\tutorial\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\.conda\\envs\\tutorial\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 13500 samples, validate on 1500 samples\n",
      "Epoch 1/20\n",
      "13500/13500 [==============================] - 1s 57us/step - loss: 0.5118 - accuracy: 0.7933 - val_loss: 0.3988 - val_accuracy: 0.8100\n",
      "Epoch 2/20\n",
      "13500/13500 [==============================] - 1s 53us/step - loss: 0.2445 - accuracy: 0.9053 - val_loss: 0.1577 - val_accuracy: 0.9613\n",
      "Epoch 3/20\n",
      "13500/13500 [==============================] - 1s 51us/step - loss: 0.1905 - accuracy: 0.9209 - val_loss: 0.1365 - val_accuracy: 0.9407\n",
      "Epoch 4/20\n",
      "13500/13500 [==============================] - 1s 53us/step - loss: 0.1626 - accuracy: 0.9307 - val_loss: 0.0996 - val_accuracy: 0.9687\n",
      "Epoch 5/20\n",
      "13500/13500 [==============================] - 1s 52us/step - loss: 0.1468 - accuracy: 0.9390 - val_loss: 0.0935 - val_accuracy: 0.9653\n",
      "Epoch 6/20\n",
      "13500/13500 [==============================] - 1s 53us/step - loss: 0.1425 - accuracy: 0.9359 - val_loss: 0.1248 - val_accuracy: 0.9373\n",
      "Epoch 7/20\n",
      "13500/13500 [==============================] - 1s 53us/step - loss: 0.1379 - accuracy: 0.9403 - val_loss: 0.0711 - val_accuracy: 0.9893\n",
      "Epoch 8/20\n",
      "13500/13500 [==============================] - 1s 50us/step - loss: 0.1306 - accuracy: 0.9430 - val_loss: 0.3326 - val_accuracy: 0.8587\n",
      "Epoch 9/20\n",
      "13500/13500 [==============================] - 1s 39us/step - loss: 0.1282 - accuracy: 0.9419 - val_loss: 0.0676 - val_accuracy: 0.9840\n",
      "Epoch 10/20\n",
      "13500/13500 [==============================] - 1s 38us/step - loss: 0.1223 - accuracy: 0.9491 - val_loss: 0.1064 - val_accuracy: 0.9473\n",
      "Epoch 11/20\n",
      "13500/13500 [==============================] - 1s 40us/step - loss: 0.1212 - accuracy: 0.9455 - val_loss: 0.1408 - val_accuracy: 0.9280\n",
      "4999/4999 [==============================] - 0s 15us/step\n",
      "loss= 0.14838450502624367\n",
      "accuracy= 0.9203840494155884\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./dataset/bmi.csv\")\n",
    "\n",
    "#키와 몸무게 정규화\n",
    "df[\"height\"] /= 200\n",
    "df[\"weight\"] /= 100\n",
    "\n",
    "X = df[[\"weight\", \"height\"]].as_matrix()\n",
    "\n",
    "#label 컬럼 변환 - thin[1, 0, 0]/normal[0, 1, 0]/fat [0, 0, 1]\n",
    "bclass = {\"thin\": [1, 0, 0] , \"normal\":[0, 1, 0], \"fat\": [0, 0, 1]}\n",
    "Y = np.empty((20000, 3))\n",
    "for i, v in enumerate(df[\"label\"]):\n",
    "    Y[i] = bclass[v]\n",
    " \n",
    "# 학습데이터 , 테스트 데이터 분리\n",
    "X_train, Y_train = X[1:15001], Y[1:15001]\n",
    "X_test, Y_test = X[15001:20001], Y[15001:20001]\n",
    "\n",
    "model = Sequential()  #모델 객체 생성\n",
    "model.add(Dense(512, input_shape=(2, )))    #Dense(노드 수 , ....) 층을 의미하는 객체\n",
    "model.add(Activation('relu'))   # 활성화 함수\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3)) # 분류하고 싶은 클래스 수 만큼 출력으로 구성\n",
    "model.add(Activation('softmax'))  #활성화 함수\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "\n",
    "#모델 훈련\n",
    "hist = model.fit(X_train, Y_train, batch_size=100, epochs=20, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=2)], verbose=1)                    \n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"loss=\", score[0])\n",
    "print(\"accuracy=\", score[1])\n",
    "\n",
    "\n",
    "\n",
    "# weight decay( 가중치 감소) - 학습중 가중치가 큰 것에 대해서 패널티를 부과해 과적합의 위험을 줄이는 방법\n",
    "# Dropout - 복잡한 신경망에서 가중치 감소만으로 과적합을 피하기 어려운 경우 뉴런의 연결을 임의로 삭제시켜 신호를 전달하지 못하도록 하는 방법\n",
    "# softmax 회귀 - 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하여 출력값들의 총합은 항상 1이 되는 특성의 함수\n",
    "#                       분류하고 싶은 클래스 수 만큼 출력으로 구성\n",
    "#                        소프트 맥스 결과값을 One hot encoder의 입력으로 연결하면 가장 큰 값만 True값, 나머지는  False값이 나오게 하여 이용 가능하다\n",
    "#val_loss는 에포크 힛수가 많아질 수록 감소하다가 다시 증가됨을 보이는 경우, 과적합이 발생한 것입니다.\n",
    "#학습에 더 이상 개선의 여지가 없을 경우 학습을 종료시키는 콜백함수(수행중인 함수에서 지정된 함수를 호출,되부름)는 EarlyStopping 입니다.\n",
    "#Dense(출력 뉴런의 수,  input_dim=입력 뉴런의 수,  init= 가중치 초기화 방법,  activation=활성화 함수)\n",
    "#relu 활성화 함수는 은닉층에 주로 사용\n",
    "#sigmoid 활성화 함수는 이진 분류 문제에서 출력층에 주로 사용\n",
    "#softmax  활성화 함수는 다중 클래스 분류 문제에서 출력층에 주로 사용\n",
    "\n",
    "# EarlyStopping (monitor=, min_delta=, patience=, verbose=, mode=)\n",
    "# monitor는 관찰하고자 하는 항목(val_loss, val_acc)\n",
    "# min_delta : 개선되고 있다고 판단하기 위한 최소 변화량\n",
    "# patience : 개선이 없어도 종료하지 않고 개선이 없는 epoch를 얼마나 기다릴 것이지 epoch수를 지정 \n",
    "# verbose : 정보 표시 상세도 (0, 1, 2)\n",
    "# mode : 관찰 항목에 개선이 없다고 판단하기 위한 기준\n",
    "\n",
    "# loss : epoch마다 훈련 손실값\n",
    "# acc :  epoch마다 훈련 정확도 값\n",
    "# val_loss :   epoch마다 검증 손실값\n",
    "# val_acc :  epoch마다  검증 정확도 값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
