{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensoflow.sqrt(x): x의 제곱근을 계산\n",
    "- tensoflow.reduce_mean(x): x의 평균을 계산\n",
    "- tensoflow.square(x): x의 제곱을 계산\n",
    "- random_uniform([1], 0, 10,…) : 0에서 10 사이에서 임의의 수 1개 생성 반환\n",
    "- Variable() : 변수의 값을 지정\n",
    "- GradientDescentOptimizer() : 경사 하강법 함수!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기본적인 데이터 사항\n",
    "data = [[2,81], [4,93], [6,91], [8,97]]\n",
    "\n",
    "# x 값과 y값\n",
    "x_data = [i[0] for i in data]\n",
    "y_data = [i[1] for i in data]\n",
    "\n",
    "# 임의의 기울기와 y절편의 값을 변수로 정의\n",
    "w = tf.Variable(tf.random_uniform([1], 0,10, dtype=tf.float64, seed = 0)) # 기울기 범위 0~10\n",
    "b = tf.Variable(tf.random_uniform([1], 0,100, dtype=tf.float64, seed = 0)) # y절편 범위 0~100\n",
    "\n",
    "y = w*x_data + b # 1차방정식의 계산식 정의\n",
    "\n",
    "# 오차 계산(평균 제곱근 오차 공식)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(y-y_data)))\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE=30.2139, 기울기 w=7.5235, 절편=80.5984\n",
      "Epoch: 100, RMSE=2.8860, 기울기 w=2.2299, 절편=79.4181\n",
      "Epoch: 200, RMSE=2.8826, 기울기 w=2.2601, 절편=79.2379\n",
      "Epoch: 300, RMSE=2.8815, 기울기 w=2.2773, 절편=79.1353\n",
      "Epoch: 400, RMSE=2.8811, 기울기 w=2.2871, 절편=79.0770\n",
      "Epoch: 500, RMSE=2.8810, 기울기 w=2.2927, 절편=79.0438\n",
      "Epoch: 600, RMSE=2.8810, 기울기 w=2.2958, 절편=79.0249\n",
      "Epoch: 700, RMSE=2.8810, 기울기 w=2.2976, 절편=79.0142\n",
      "Epoch: 800, RMSE=2.8810, 기울기 w=2.2987, 절편=79.0081\n",
      "Epoch: 900, RMSE=2.8810, 기울기 w=2.2992, 절편=79.0046\n",
      "Epoch: 1000, RMSE=2.8810, 기울기 w=2.2996, 절편=79.0026\n",
      "Epoch: 1100, RMSE=2.8810, 기울기 w=2.2998, 절편=79.0015\n",
      "Epoch: 1200, RMSE=2.8810, 기울기 w=2.2999, 절편=79.0008\n",
      "Epoch: 1300, RMSE=2.8810, 기울기 w=2.2999, 절편=79.0005\n",
      "Epoch: 1400, RMSE=2.8810, 기울기 w=2.3000, 절편=79.0003\n",
      "Epoch: 1500, RMSE=2.8810, 기울기 w=2.3000, 절편=79.0002\n",
      "Epoch: 1600, RMSE=2.8810, 기울기 w=2.3000, 절편=79.0001\n",
      "Epoch: 1700, RMSE=2.8810, 기울기 w=2.3000, 절편=79.0001\n",
      "Epoch: 1800, RMSE=2.8810, 기울기 w=2.3000, 절편=79.0000\n",
      "Epoch: 1900, RMSE=2.8810, 기울기 w=2.3000, 절편=79.0000\n",
      "Epoch: 2000, RMSE=2.8810, 기울기 w=2.3000, 절편=79.0000\n"
     ]
    }
   ],
   "source": [
    "# 이 코드가 하는 일은 손실함수 모델 파라메타 a, b에 대해, 손실 함수 rmse의 미분을 구하여 각각 a와 b에 업데이트 하는 것입니다. \n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 텐서플로로 학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  # 변수들을 메모리에 생성, 초기화\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE=%.4f, 기울기 w=%.4f, 절편=%.4f\" %(step, sess.run(rmse), sess.run(w), sess.run(b)))\n",
    "            \n",
    "# Epoch는 입력값에 대해 몇 번 반복되어 있는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE=171793.5781, 기울기 w=88.1365, 절편=17.1673\n",
      "Epoch: 100, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 200, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 300, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 400, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 500, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 600, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 700, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 800, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 900, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1000, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1100, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1200, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1300, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1400, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1500, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1600, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1700, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1800, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 1900, RMSE=nan, 기울기 w=nan, 절편=nan\n",
      "Epoch: 2000, RMSE=nan, 기울기 w=nan, 절편=nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 위의 train.GradientDescentOptimizer() 메서드를 쓰는 대신에 이렇게 해도 됌\n",
    "import matplotlib.pyplot as plt\n",
    "g1 = tf.Graph() \n",
    "with g1.as_default():\n",
    "    W = tf.Variable(tf.random_uniform([1], -1.0, 1.0)) \n",
    "    b = tf.Variable(tf.zeros([1])) \n",
    "    y = W * x_data + b \n",
    "    loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "    dW, db = tf.gradients(loss, [W, b]) \n",
    "    update_W = tf.assign(W, W - 0.1 * dW) \n",
    "    update_b = tf.assign(b, b - 0.1 * db)\n",
    "\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run([update_W, update_b, loss, y])\n",
    "        sess.run([W, b])\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE=%.4f, 기울기 w=%.4f, 절편=%.4f\" %(step, sess.run(loss), sess.run(W), sess.run(b)))\n",
    "        # 산포도 그리기\n",
    "        plt.plot(x_data, y_data, 'ro')\n",
    "        # 직선 그리기\n",
    "#         plt.plot(x_data, W * x_data + b)\n",
    "\n",
    "######################################################################\n",
    "# da, db = tf.gradients(rmse, [a, b])\n",
    "# update_a = tf.assign(a, a - 0.5 * da)\n",
    "# update_b = tf.assign(b, b - 0.5 * db)\n",
    "#######################################################################\n",
    "# tf.gradients에 두 번째 매개변수로 여러개의 텐서를 리스트로 넘겨서 한번에 여러개의 그래디언트를 구할 수 있습니다.\n",
    "# a와 b는 변수이기 때문에 직접 값을 대입할 수 없고 tf.assign 함수를 사용합니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 모델을 훈련시킨다는 것은 데이터 이용해 오차를 구하고 오차에 대한 그래디언트를 계산해서 모델 파라미터를 업데이트 하는 것입니다.\n",
    "# 텐서플로우로 실행할 작업은 모델 파라미터를 업데이트 하는 update_w와 update_b 텐서를 실행하는 일입니다.\n",
    "\n",
    "# Epoch는 입력값에 대해 몇 번 반복되어 있는지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, RMSE=49.1842, 기울기1 a1=7.5270, 기울기2 a2=7.8160, 절편=80.5980\n",
      "Epoch: 100, RMSE=1.8368, 기울기1 a1=1.1306, 기울기2 a2=2.1316, 절편=78.5119\n",
      "Epoch: 200, RMSE=1.8370, 기울기1 a1=1.1879, 기울기2 a2=2.1487, 절편=78.1057\n",
      "Epoch: 300, RMSE=1.8370, 기울기1 a1=1.2122, 기울기2 a2=2.1571, 절편=77.9352\n",
      "Epoch: 400, RMSE=1.8370, 기울기1 a1=1.2226, 기울기2 a2=2.1607, 절편=77.8636\n",
      "Epoch: 500, RMSE=1.8370, 기울기1 a1=1.2269, 기울기2 a2=2.1622, 절편=77.8335\n",
      "Epoch: 600, RMSE=1.8370, 기울기1 a1=1.2288, 기울기2 a2=2.1628, 절편=77.8208\n",
      "Epoch: 700, RMSE=1.8370, 기울기1 a1=1.2295, 기울기2 a2=2.1631, 절편=77.8155\n",
      "Epoch: 800, RMSE=1.8370, 기울기1 a1=1.2299, 기울기2 a2=2.1632, 절편=77.8133\n",
      "Epoch: 900, RMSE=1.8370, 기울기1 a1=1.2300, 기울기2 a2=2.1632, 절편=77.8124\n",
      "Epoch: 1000, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8120\n",
      "Epoch: 1100, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8118\n",
      "Epoch: 1200, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 1300, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 1400, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 1500, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 1600, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 1700, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 1800, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 1900, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n",
      "Epoch: 2000, RMSE=1.8370, 기울기1 a1=1.2301, 기울기2 a2=2.1633, 절편=77.8117\n"
     ]
    }
   ],
   "source": [
    "data = [[2,0,81], [4,4,93], [6,2,91], [8,3,97]]\n",
    "\n",
    "# x 값과 y값\n",
    "x1_data = [i[0] for i in data]\n",
    "x2_data = [i[1] for i in data]\n",
    "y_data = [i[2] for i in data]\n",
    "\n",
    "# 임의의 기울기와 y절편의 값을 변수로 정의\n",
    "a1 = tf.Variable(tf.random_uniform([1], 0,10, dtype=tf.float64, seed = 0)) # 기울기 범위 0~10\n",
    "a2 = tf.Variable(tf.random_uniform([1], 0,10, dtype=tf.float64, seed = 0)) # 기울기 범위 0~10\n",
    "b = tf.Variable(tf.random_uniform([1], 0,100, dtype=tf.float64, seed = 0)) # y절편 범위 0~100\n",
    "\n",
    "y = a1*x1_data + a2*x2_data + b # 1차방정식의 계산식 정의\n",
    "\n",
    "# 오차 계산(평균 제곱근 오차 공식)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(y-y_data)))\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 오차 rmse 값이 최소인 값 찾기\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "\n",
    "# 텐서플로로 학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  # 변수들을 멤리에 생성, 초기화\n",
    "    for step in range(2001):\n",
    "        sess.run(gradient_descent)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Epoch: %.f, RMSE=%.4f, 기울기1 a1=%.4f, 기울기2 a2=%.4f, 절편=%.4f\" %(step, sess.run(rmse), sess.run(a1), sess.run(a2), sess.run(b)))\n",
    "            \n",
    "# Epoch는 입력값에 대해 몇 번 반복되어 있는지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
