# 전 수업 복습

## 1. 퍼셉트론

> 입력값과 활성화 함수를 사용해서 출력 값을 다음으로 넘기는 가장 작은 인공 신경망 단위

- N개의 2진수가 하나의 뉴런을 통과해서 가중합이 0보다 크면 활성화되는 가장 간단한 신경망 구조
- 초평면(hyperplane)으로 구분되는 두 개의 공간을 분리하는 역할--> And게이트, OR게이트를 만들 수 있다.
- XOR게이트를 퍼셉트론으로 구현하기 위해서는 좌표평면 자체에 공간을 주는 은닉층을 만들어서 공간을 왜곡하면 두 영역으로 분류가 가능한데 **두 개의 퍼셉트론을 한 번에 계산할 수 있어야 합니다.**

- *퍼셉트론 신경망 수행 흐름* :

  1) 환경변수 지정 : 출력 뉴런 수, 입력 데이터에 적용할 가중치, 가중합에 적용될 바이어스, 활성화 함수, 은닉층 수

  2) 신경망 실행

  3) 결과를 실제값과 비교

  4) 3)에서 계산된 오차를 보고 출력층과 은닉층의 가중치를 수정(using 오차 역전파)

  5) 신경망 실행

  6) 위의 과정을 계속해서 반복

  7) 결과 출력(분류, 예측)

------------



은닉층으로의 출력에 사용될 활성화 함수 : 처음엔 sigmoid였다가 기울기 소실 문제를 해결해주는 **ReLU**를 사용

출력층에 사용될 활성화 함수 : sigmoid(이항분류), softmax(다항분류), 선형회귀(연속형변수의 값 예측)



[**성능 최적화 함수**]

모든 데이터에 대해서 미분값 계산은 수행 속도 저하가 발생 -->  랜덤하게 추출한 일부 데이터를 사용해서 더 빠르게 수행(SGD : 확률적 경사하강법)

모멘텀 - 관성을 이용하여 방향을 고려해서 진동 폭을 줄이기 위해 사용

알엠에스프롬(RMSprop) - 아다그라드 보폭 민감도를 보완한 방법

아담 - 모멘텀 + 알엠에스프롭(RMSprop)



Sequential() : keras에서 제공하는 모델 구조를 구성할 수 있는 객체

add(Dense(출력뉴런수 ,input_dim= , init= , activation=)) : 입력층 --> 은닉층 구조(layer)

add(Dense(출력뉴런수,  activation= )) : 은닉층 --> 은닉층 구조(layer)

add(Dense(1,  activation= )) : 은닉층 --> 출력층 구조(layer)



1epoch : 학습 프로세스에서 모든 샘플에 대해서 한 번 실행되는 것

다중 분류시에 class가 object 타입으로 thin, normal, fat --> 정수변환(LabelEncoder) --> one-hot-encoding 변환(keras.utils.np_utils.to_categorial())



Sequential() 를 이용해서 신경망 layer 구성 후

compile(loss= 오차함수, optimizer = 성능최적화 함수, metrics = 정확도, 재현율 등 측정함수) 

fit(독립변수 데이터 객체, 종속변수 데이터 객체, epochs = , batch_size = ) : 학습



[오차 함수]

mean_squared_error :  평균 제곱 오차

mean_absolute_error : 평균 절대 오차

mean_absolute_percentage_error : 평균 절대 백분율 오차

mean_squared_logarithmetic_error : 평균 제곱 로그 오차

분류 문제에서 정확률과 재현률 측정 - categorial_crossentropy(범주형 교차 엔트로피), binary_crossentropy(이항 교차 엔트로피)



train_test_split(독립변수데이터 객체, 종속변수 데이터 객체, test_size= , random_state = ) : 학습데이터와 테스트 데이터 분리



학습 결과 모델을 저장  : save()

학습 결과 모델을 메모리로 로딩 : load_model()



**k-겹 교차 검증** - 학습데이터(테스트 데이터)가 적은 경우, 데이터셋으 여러 개로 나누어 하나씩 테스트 셋으로 사용(전체 데이터셋으로 사용할 수 있음)    *sklearn.model_selectionStratifiedKFold(n_splits= , shuffle= , random_state = )* 



Keras.callbacks.ModelCheckpoint(filepath = , monitor = , verbose =, save_best_only= ) : Epoch마다 모델의 정확도를 저장

Epoch마다 생성된 모델 객체에는 배열로 학습 정확도, 검증 정확도, 학습 손실값, 검증 손실값 val_loss

과적합이 발생 : 생성된 모델 객체의 테스트의 오차 속성 val_loss 값이 감소하다가 다시 증가하기 시작하는 시점

과적합이 발생하면 신경망 학습 수행 중단 : EarlyStopping(monitor = 'val_loss', patience = )

Dense Layer마다 출력 뉴런수 설정(제약이 없다)

Dense Layer 구조, 개수 등의 설정에 따라 모델의 성능이 달라짐 --> Dense 생성시에 변경가능한 옵션들, Layer수 등을 조정해서 튜닝합니다.(hyperparameter 튜닝)

fit() 의 기본 로그는 손실값과 정확도가 표시됩니다.

2진 분류는 정확도를 통해서 제대로 학습이 되고 있는지 확인 가능함

다중 분류는 정확도, 재현율 등을 통해서 학습이 되고 있는지 확인 가능

metrics 는 평가 기준



evaluate() : 손실값, metrics 값 등을 반환 --> 모델을 평가







